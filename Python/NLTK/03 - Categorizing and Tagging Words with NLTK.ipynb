{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing and Tagging Words with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tag our tokens (words) in order to analyze the text morphologically, it is, to make sense of the context in which the word is appearing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text = 'We are learning Natural Languages Processing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have tokenized our text, we use <b>POS tagger</b> in order to add a tag to each word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('We', 'PRP'), ('are', 'VBP'), ('learning', 'VBG'), ('Natural', 'NNP'), ('Languages', 'NNP'), ('Processing', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we donÂ´t know what the Tags mean, we can use nltk help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('PRP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now we can search trough a corpus (we will use brown) to find words in the same context, using <b>.similar</b> method:\n",
    "\n",
    "*From the documentation:\n",
    "\n",
    "+  .similar(): find other words which appear in the\n",
    "same contexts as the specified word; list most similar words first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply it to the word \"woman\":\n",
    "\n",
    "which type of word is \"woman\"?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 'NN')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we use .similar():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man time day year car moment world house family child country boy\n",
      "state job place way war girl work word\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made said done put had seen found given left heard was been brought\n",
      "set got that took in told felt\n"
     ]
    }
   ],
   "source": [
    "text.similar('bought')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Tagged Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a text in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''\n",
    "The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN\n",
    "... other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC\n",
    "... Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS\n",
    "... said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB\n",
    "... accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT\n",
    "... interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new object of tuples (word, tag):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('grand', 'JJ'), ('jury', 'NN'), ('commented', 'VBD'), ('on', 'IN'), ('a', 'AT'), ('number', 'NN'), ('of', 'IN'), ('...', None), ('other', 'AP'), ('topics', 'NNS'), (',', ','), ('AMONG', 'IN'), ('them', 'PPO'), ('the', 'AT'), ('Atlanta', 'NP'), ('and', 'CC'), ('...', None), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('purchasing', 'VBG'), ('departments', 'NNS'), ('which', 'WDT'), ('it', 'PPS'), ('...', None), ('said', 'VBD'), ('``', '``'), ('ARE', 'BER'), ('well', 'QL'), ('operated', 'VBN'), ('and', 'CC'), ('follow', 'VB'), ('generally', 'RB'), ('...', None), ('accepted', 'VBN'), ('practices', 'NNS'), ('which', 'WDT'), ('inure', 'VB'), ('to', 'IN'), ('the', 'AT'), ('best', 'JJT'), ('...', None), ('interest', 'NN'), ('of', 'IN'), ('both', 'ABX'), ('governments', 'NNS'), (\"''\", \"''\"), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_Sentence = [nltk.tag.str2tuple(token) for token in sentence.split()]\n",
    "print(tagged_Sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK corpus has his own tagged corpus, using .tagged_words():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Default Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is going to tag <b>each word</b> (all of them) with the tag we give it as an input:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to tag the following text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = 'We are learning taggers right now and aim to build applications which uses language to perform analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to tokenize our text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_tokens = nltk.word_tokenize(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could give it as an input whatever string to tag our text, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('We', 'OurTag'), ('are', 'OurTag'), ('learning', 'OurTag'), ('Natural', 'OurTag'), ('Languages', 'OurTag'), ('Processing', 'OurTag')]\n"
     ]
    }
   ],
   "source": [
    "default_tagger = nltk.DefaultTagger('OurTag')\n",
    "print(default_tagger.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, let use the most common tag in the <b>news category</b> from the <b>brown corpus</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN\n"
     ]
    }
   ],
   "source": [
    "tags = [tag for (word, tag) in nltk.corpus.brown.tagged_words(categories='news')] # create a list of tags from the corpus\n",
    "print(nltk.FreqDist(tags).max()) # print the most common tag in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('We', 'NN'), ('are', 'NN'), ('learning', 'NN'), ('Natural', 'NN'), ('Languages', 'NN'), ('Processing', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "default_tagger = nltk.DefaultTagger(nltk.FreqDist(tags).max()) # creating our tagger\n",
    "print(default_tagger.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing this, we are assigning a wrong tag to the majority of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating our tagger performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use .evaluate():\n",
    "\n",
    "from the documentation:\n",
    "* default_tagger.evaluate(gold)\n",
    "    * :type gold: list(list(tuple(str, str)))\n",
    "    * :param gold: The list of tagged sentences to score the tagger on.\n",
    "\n",
    "Explaination: we apply .evaluate() over a test set of tagged sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13089484257215028\n"
     ]
    }
   ],
   "source": [
    "print(default_tagger.evaluate(nltk.corpus.brown.tagged_sents(categories='news')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see it's a very poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegExp Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RegexpTagger assigns tags to tokens by comparing their\n",
    "word strings to a series of regular expressions.\n",
    "\n",
    "From the documentation:\n",
    "\n",
    "- nltk.RegexpTagger(regexps, backoff=None)\n",
    "    - :type regexps: list(tuple(str, str))\n",
    "    - :param regexps: A list of ``(regexp, tag)`` pairs, each of which indicates that a word matching ``regexp`` should be tagged with ``tag``.  The pairs will be evalutated in order.\n",
    "    - :param backoff: If none of the regexps match a word, then the optional backoff tagger is invoked, else it is assigned the tag None.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a list of RegEx patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [(r'.*ing$', 'VBG'), (r'.*ed$', 'VBD'), (r'.*es$', 'VBZ'), (r'.*ould$', 'MD'), (r'.*\\'s$', 'NN$'),\n",
    "             (r'.*s$', 'NNS'),  (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), (r'.*', 'NN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create and use our tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('We', 'NN'), ('are', 'NN'), ('learning', 'VBG'), ('taggers', 'NNS'), ('right', 'NN'), ('now', 'NN'), ('and', 'NN'), ('aim', 'NN'), ('to', 'NN'), ('build', 'NN'), ('applications', 'NNS'), ('which', 'NN'), ('uses', 'VBZ'), ('language', 'NN'), ('to', 'NN'), ('perform', 'NN'), ('analysis', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "print(regexp_tagger.tag(raw_text_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UnigramTagger finds the most likely tag for each word in a training corpus, and then uses that information to assign tags to new tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use it, we will have to give it a set of tagged sentences that it will use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged_sents = nltk.corpus.brown.tagged_sents(categories = 'news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we create and train our tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train=brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('We', 'PPSS'), ('are', 'BER'), ('using', 'VBG'), ('the', 'AT'), ('programming', None), ('language', 'NN'), ('Python', None)]\n"
     ]
    }
   ],
   "source": [
    "print(unigram_tagger.tag(nltk.word_tokenize('We are using the programming language Python')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating our Unigram Tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9349006503968017\n"
     ]
    }
   ],
   "source": [
    "print(unigram_tagger.evaluate(brown_tagged_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not bad! but <u>we were testing it over our training set!!!</u>\n",
    "\n",
    "We should split our set into **Train** and **Test** sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "train_sentences = brown_tagged_sents[:size]\n",
    "test_sentences = brown_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to **train again** our tagger, using our **train set**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we **test it again**, over our **Test set**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8121200039868434\n"
     ]
    }
   ],
   "source": [
    "print(unigram_tagger.evaluate(test_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is more realistic now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n-gram**: a sequential list of n words, used to encode the likelihood that the phrase will appear in the future. So it takes in account **the context** where the word is in.\n",
    "\n",
    "From documentation:\n",
    "- N-gram tagger is a tagger that chooses a token's tag based on its word string and on the preceding n word's tags.  In , a tuple (tags[i-n:i-1], words[i]) is looked up in a table, and the corresponding tag is returned.  N-gram taggers are typically trained on a tagged corpus.\n",
    "\n",
    "It simply involves splitting the sentence into chunks of consecutive words of lenght \"n\"\n",
    "\n",
    "- For example: \"I don't know what to say\"\n",
    "\n",
    "    - 1-gram (unigram): I, don't, know, what, to, say\n",
    "    - 2-gram (bigram): I don't, don't know, know what, what to, to say\n",
    "    - 3-gram (trigram): I don't know, don't know what, know what to, what to say\n",
    "    - ...\n",
    "    - n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('We', 'PPSS'), ('are', 'BER'), ('using', None), ('the', None), ('programming', None), ('language', None), ('Python', None)]\n"
     ]
    }
   ],
   "source": [
    "ngram_tagger = nltk.NgramTagger(len(brown_tagged_sents),train=brown_tagged_sents)\n",
    "print(ngram_tagger.tag(nltk.word_tokenize('We are using the programming language Python')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating our N-gram Tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9441841921658527\n"
     ]
    }
   ],
   "source": [
    "print(ngram_tagger.evaluate(test_sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
